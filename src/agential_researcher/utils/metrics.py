from prometheus_client import Counter, Histogram, Gauge
from typing import Dict, Any
import time

# Request metrics
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint']
)

# LLM provider metrics
PROVIDER_REQUESTS = Counter(
    'llm_provider_requests_total',
    'Total requests to LLM providers',
    ['provider', 'model', 'endpoint']
)

PROVIDER_ERRORS = Counter(
    'llm_provider_errors_total',
    'Total errors from LLM providers',
    ['provider', 'error_type']
)

TTFT_HISTOGRAM = Histogram(
    'llm_time_to_first_token_seconds',
    'Time to first token in seconds',
    ['provider'],
    buckets=[0.1, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 3.0, 5.0, 10.0, 20.0, 30.0]
)

TOKENS_GENERATED = Counter(
    'llm_generated_tokens_total',
    'Total tokens generated by LLM',
    ['provider']
)

TOKENS_PROMPT = Counter(
    'llm_prompt_tokens_total',
    'Total prompt tokens sent to LLM',
    ['provider']
)

# Queue metrics
QUEUE_DEPTH = Gauge(
    'queue_depth',
    'Current queue depth',
    ['queue_name']
)

TASK_DURATION = Histogram(
    'celery_task_duration_seconds',
    'Duration of Celery tasks in seconds',
    ['task_name']
)

# Database metrics
DB_QUERIES = Counter(
    'database_queries_total',
    'Total database queries',
    ['operation']
)

DB_ERRORS = Counter(
    'database_errors_total',
    'Total database errors',
    ['operation', 'error_type']
)

# Application metrics
ITEMS_PROCESSED = Counter(
    'items_processed_total',
    'Total items processed',
    ['source', 'operation']
)

def time_llm_request(provider: str, model: str, endpoint: str, duration: float):
    """Record metrics for LLM provider requests"""
    PROVIDER_REQUESTS.labels(provider=provider, model=model, endpoint=endpoint).inc()
    if duration:
        TTFT_HISTOGRAM.labels(provider=provider).observe(duration)

def count_tokens(provider: str, prompt_tokens: int, generated_tokens: int):
    """Record token usage metrics"""
    if prompt_tokens:
        TOKENS_PROMPT.labels(provider=provider).inc(prompt_tokens)
    if generated_tokens:
        TOKENS_GENERATED.labels(provider=provider).inc(generated_tokens)

def record_task_duration(task_name: str, duration: float):
    """Record task duration"""
    TASK_DURATION.labels(task_name=task_name).observe(duration)

def update_queue_depth(queue_name: str, depth: int):
    """Update queue depth metric"""
    QUEUE_DEPTH.labels(queue_name=queue_name).set(depth)

def record_db_operation(operation: str, has_error: bool = False, error_type: str = None):
    """Record database operation metrics"""
    if has_error:
        DB_ERRORS.labels(operation=operation, error_type=error_type).inc()
    else:
        DB_QUERIES.labels(operation=operation).inc()

def record_item_processed(source: str, operation: str):
    """Record items processed"""
    ITEMS_PROCESSED.labels(source=source, operation=operation).inc()